#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
The same STA/LTA as used in Flexwin.

:copyright:
    Lion Krischer (krischer@geophysik.uni-muenchen.de), 2014
:license:
    GNU General Public License, Version 3
    (http://www.gnu.org/copyleft/gpl.html)
"""
from __future__ import (absolute_import, division, print_function,
                        unicode_literals)
from future.builtins import *  # NOQA

import numpy as np
from scipy.signal import lfilter
from obspy.signal.headers import clibsignal, head_stalta_t
############################## original ############################
#def sta_lta(data, dt, main_period):
#    """
#    STA/LTA as used in FLEXWIN.
#
#    :param data: The data array.
#    :param dt: The sample interval of the data.
#    :param main_period: The main period of the data.
#    """
#    Cs = 10 ** (-dt / main_period)
#    Cl = 10 ** (-dt / (12 * main_period))
#    print('Cs',Cs)
#    print('Cl',Cl)
#    TOL = 1e-9
#    noise = data.max() / 1E5
#    print('noise',noise)
#
#    # 1000 samples should be more then enough to "warm up" the STA/LTA.
#    extended_syn = np.zeros(len(data) + 1000, dtype=np.float64)
#    # copy the original synthetic into the extended array, right justified
#    # and add the noise level.
#    extended_syn += noise
#    extended_syn[-len(data):] += data
#
#    # This piece of codes "abuses" SciPy a bit by "constructing" an IIR
#    # filter that does the same as the decaying sum and thus avoids the need to
#    # write the loop in Python. The result is a speedup of up to 2 orders of
#    # magnitude in common cases without needing to write the loop in C which
#    # would have a big impact in the ease of installation of this package.
#    # Other than that its quite a cool little trick.
#    a = [1.0, -Cs]
#    b = [1.0]
#    sta = lfilter(b, a, extended_syn)
#
#    a = [1.0, -Cl]
#    b = [1.0]
#    lta = lfilter(b, a, extended_syn)
#
#    print('sta',sta)
#    print('lta',lta)
#    # STA is now STA_LTA
#    sta /= lta
#
#    # Apply threshold to avoid division by very small values.
#    sta[lta < TOL] = noise
#	########## Normalize ##########
#    sta /= max(abs(sta))
#	########## Normalize ##########
#    return sta[-len(data):]
############################## original ############################

############################ carl_sta_trig##########################
def sta_lta(a, dt, main_period):
    """
    Computes the carlSTAtrig characteristic function.

    eta = star - (ratio * ltar) - abs(sta - lta) - quiet

    :type a: NumPy :class:`~numpy.ndarray`
    :param a: Seismic Trace
    :type nsta: int
    :param nsta: Length of short time average window in samples
    :type nlta: int
    :param nlta: Length of long time average window in samples
    :type ration: float
    :param ratio: as ratio gets smaller, carl_sta_trig gets more sensitive
    :type quiet: float
    :param quiet: as quiet gets smaller, carl_sta_trig gets more sensitive
    :rtype: NumPy :class:`~numpy.ndarray`
    :return: Characteristic function of CarlStaTrig
    """

    ######## Need change later########
#    print(main_period)
#    print(dt)
    nsta=1*int(main_period/dt)
    nlta=3*nsta      #nlta=5*nsta
#    print(main_period)
#    print(nlta)
    ratio=0.0
    quiet=0.0
	######## Need change later########
    m = len(a)
#    print('a = ',a)
    #
    sta = np.zeros(len(a), dtype=np.float64)
    lta = np.zeros(len(a), dtype=np.float64)
    star = np.zeros(len(a), dtype=np.float64)
    ltar = np.zeros(len(a), dtype=np.float64)
    pad_sta = np.zeros(nsta)
    pad_lta = np.zeros(nlta)  # avoid for 0 division 0/1=0
    #
    # compute the short time average (STA)
    for i in range(nsta):  # window size to smooth over
        sta += np.concatenate((pad_sta, a[i:m - nsta + i]))
    sta /= nsta
    #
    # compute the long time average (LTA), 8 sec average over sta
    for i in range(nlta):  # window size to smooth over
        lta += np.concatenate((pad_lta, sta[i:m - nlta + i]))
    lta /= nlta
    lta = np.concatenate((np.zeros(1), lta))[:m]  # XXX ???
    #
    # compute star, average of abs diff between trace and lta
    for i in range(nsta):  # window size to smooth over
        star += np.concatenate((pad_sta,
                               abs(a[i:m - nsta + i] - lta[i:m - nsta + i])))
    star /= nsta
    #
    # compute ltar, 8 sec average over star
    for i in range(nlta):  # window size to smooth over
        ltar += np.concatenate((pad_lta, star[i:m - nlta + i]))
    ltar /= nlta
    #
    eta = star - (ratio * ltar) - abs(sta - lta) - quiet
    eta[:nlta] = 0.0
	########## Normalize ##########
    eta /= max(abs(eta))
	########## Normalize ##########
	########## Add water level, make sure the min value larger than 0 ##########
    eta = eta - min(eta)*np.ones(len(a), dtype=np.float64)
	########## Add water level, make sure the min value larger than 0 ##########
#    print(eta)
    return eta
############################ carl_sta_trig##########################


########################### classic_sta_lta##########################
#def sta_lta(a, dt, main_period):
#    """
#    Computes the standard STA/LTA from a given input array a. The length of
#    the STA is given by nsta in samples, respectively is the length of the
#    LTA given by nlta in samples.
#
#    Fast version written in C.
#
#    :type a: NumPy :class:`~numpy.ndarray`
#    :param a: Seismic Trace
#    :type nsta: int
#    :param nsta: Length of short time average window in samples
#    :type nlta: int
#    :param nlta: Length of long time average window in samples
#    :rtype: NumPy :class:`~numpy.ndarray`
#    :return: Characteristic function of classic STA/LTA
#    """
#    ######## Need change later########
#    nsta=2*int(main_period/dt)
#    nlta=5*nsta
#    print('nsta',nsta)
#    print('nlta',nlta)
#    ######## Need change later########
#    data = a
#    #print(data)
#    # initialize C struct / NumPy structured array
#    head = np.empty(1, dtype=head_stalta_t)
#    head[:] = (len(data), nsta, nlta)
#    # ensure correct type and contiguous of data
#    data = np.ascontiguousarray(data, dtype=np.float64)
#    # all memory should be allocated by python
#    charfct = np.empty(len(data), dtype=np.float64)
#    # run and check the error-code
#    errcode = clibsignal.stalta(head, data, charfct)
#    if errcode != 0:
#        raise Exception('ERROR %d stalta: len(data) < nlta' % errcode)
#	########## Normalize ##########
#    charfct /= max(abs(charfct))
#	########## Normalize ##########
#    #charfct[:nlta] = 0.0
#    #print(charfct)
#    return charfct
########################### classic_sta_lta##########################

